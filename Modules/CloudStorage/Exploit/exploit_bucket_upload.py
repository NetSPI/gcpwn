from Modules.CloudStorage.utils.util_helpers import *

# Entrypoint
def run_module(user_args, session, first_run = False, last_run = False, callback = False):

    # Set up Argparser to handle flag arguments
    parser = argparse.ArgumentParser(description="Exploit Bucket Upload", allow_abbrev=False)
    
    # Debug/non-module specific
    parser.add_argument("-v","--debug",action="store_true",required=False,help="Get verbose data during the module run")
    
    # Module specific arguments
    parser.add_argument("--bucket", type=str, required=False,  help="Bucket name to get metadata for (no gs:// prefix, just name)")
       
    upload_style_group = parser.add_mutually_exclusive_group(required = False)
    upload_style_group.add_argument("--local-blob-path",type=str, required=False, help = "Filepath of file to upload to bucket (ex. ~/myfile.txt)")
    upload_style_group.add_argument("--data-string-base64",type=str, required=False, help = "Base64 Encoded Value you want to upload to bucket (will be decoded on upload) (ex. dGVzdDM=)")

    parser.add_argument("--remote-blob-path",type=str, required=False, help = "Full path name for file on remote S3 (ex. mycoolfile/file.txt)")

    parser.add_argument("--access-id", type=str,  help="Access ID for HMAC key to use in Request")
    parser.add_argument("--hmac-secret", type=str,  help="HMAC Secret to use when making API call")

    args = parser.parse_args(user_args)
    
    debug = args.debug

    status, data_string, local_blob_path, data_string_base64 = None, None, None, None

    if args.bucket:

        bucket_name = args.bucket

        # See if we arleady have it stored otherwise project Id is unknown
        rows_returned = session.get_data("cloudstorage-buckets", columns = ["project_id"], condtions = f"name = {bucket_name}")
        if rows_returned:
            project_id = rows_returned[0]["project_id"]
        else:
            project_id = "Unknown"

    else:
        rows_returned = session.get_data("cloudstorage-buckets", columns = ["name", "project_id"])
        if len(rows_returned) == 0:
            print("[X] No buckets were found when running the module. Consider passing in all flags (--bucket, --local-blob-path, and --local-blob-path) when running the module again")
            return -1

        # Return dictionary corresponding to user choice
        row_returned = session.choice_selector(rows_returned,"Choose an existing known bucket from below. If needed consider running 'enum_buckets' before this module:", fields=["name"])
        
        if row_returned:
            # Get name field from bucket dictionary
            bucket_name = row_returned["name"]
            project_id = row_returned["project_id"]
        else:
            print("[*] Exiting Module ... ")
            return -1

    action_dict = {}

    if args.hmac_secret and args.access_id:
        storage_client = None

    elif project_id != "Unknown":
        storage_client = storage.Client(credentials = session.credentials, project = project_id)    

    else:
        storage_client = storage.Client(credentials = session.credentials)    


    if args.local_blob_path:
        local_blob_path = args.local_blob_path

    elif args.data_string_base64:
        data_string_base64 = args.data_string_base64

    else:
        row_returned = session.choice_selector(["Local File", "STDIN String"],"Do you want to upload a local file, or pass in the contents via command line (stdin)?")

        if row_returned == "Local File":
            path_found = False
            while not path_found:
                local_blob_path = session.choice_prompt("Enter a local file path for the file (ex. /home/kali/myfile.txt) you want to upload: ")
                if local_blob_path == "ls" or local_blob_path == "pwd":
                    os.system(local_blob_path)
                else:
                    path_found = True
        elif row_returned == "STDIN String":
            data_string_base64 = session.choice_prompt("Enter the Base64 encoded data of what you want to upload to the file: ")

    if data_string_base64:
        data_string_base = base64.b64decode(data_string_base64)
        data_string = data_string_base.decode('utf-8')

    if args.remote_blob_path:
        remote_blob_path = args.remote_blob_path
    else:
        remote_blob_path = session.choice_prompt("Enter a file path you want to store the impacted file at (ex. directoryone/myfile.txt): ")

      
    print(f"[*] Uploading {local_blob_path} to bucket {bucket_name} at {remote_blob_path}...")

    if debug:
        print("[DEBUG] Arguments on final call:")
        print(f"[DEBUG] Bucket Name: {bucket_name}")
        print(f"[DEBUG] Local File Path: {local_blob_path}")
        print(f"[DEBUG] Remote File Path: {remote_blob_path}")

    # currently dont support stdin for HAMC TODO
    if args.hmac_secret and args.access_id:
        status = hmac_upload_to_bucket(bucket_name, local_blob_path, remote_blob_path, project_id, debug=debug)

    else:

        if data_string:
            status = upload_to_bucket(storage_client, bucket_name, remote_blob_path, data_string = data_string, debug=debug)
        elif local_blob_path:
            status = upload_to_bucket(storage_client, bucket_name, remote_blob_path, local_blob_path = local_blob_path, debug=debug)

    if status:
        print(UtilityTools.GREEN+ UtilityTools.BOLD +f"[*] Successful upload..."+ UtilityTools.RESET)
        if not args.hmac_secret and not args.access_id:
            action_dict.setdefault(project_id, {}).setdefault("storage.objects.create", {}).setdefault("buckets", set()).add(bucket_name)
    else:
        print(f"{UtilityTools.RED}{UtilityTools.BOLD}[X] Failed upload..."{UtilityTools.RESET})

    session.insert_actions(action_dict,column_name = "storage_actions_allowed")

    if callback:
        return [bucket_name, local_blob_path, remote_blob_path]


